{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca1181e-4ff4-4d6b-99ce-7d74f4b95bda",
   "metadata": {},
   "source": [
    "# simple model\n",
    "This is a simple NN model. It takes in a long paragraph, break into separate sentences, predict probability of mistakes for each sentence, and combine the probability with OR-like function to get the final probability of whether the paragraph contains misconception/vague knowledge. Then, the result is compared to the paragraph-level label and do backward propagation. Use BERT-base-uncased as base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c09b83-2b5c-4e91-99be-9d7224f621c0",
   "metadata": {},
   "source": [
    "### install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d415694-0067-4a4f-a837-1aa4381ddf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Using cached lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, lxml, python-docx\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "Successfully installed lxml-5.3.0 python-docx-1.1.2 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecbf8b-8461-46bf-8aaf-bbdc8274b32e",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f390701e-931f-40e2-871a-70ed7c6461b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import docx\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d194036c-8d27-471b-9aeb-2e8361b715ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba6d701-d9f0-46a1-92ca-6fecfb988a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions\n",
    "# verify dir name, make sure it ends with one '/'\n",
    "def dir_valid(input_dir):\n",
    "  if input_dir[-1]!='/':\n",
    "    input_dir = input_dir + '/'\n",
    "  return input_dir\n",
    "\n",
    "# generate file name from year and month\n",
    "def get_file_unit(yr, mt, header='RS_'):\n",
    "  if isinstance(mt, int):\n",
    "    file_unit = header + str(yr) + '-' + str(mt).zfill(2)\n",
    "  else:\n",
    "    file_unit = header + str(yr) + '-' + mt\n",
    "  return file_unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e508a98-fdc5-40a3-b409-23c725201ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aaae9b-7755-4476-b233-b1e4ff54dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "# read from file RS_2023-04_records.json\n",
    "file_unit = get_file_unit('2023', 4)\n",
    "file_json = file_unit + '_records.json'\n",
    "\n",
    "df = pd.read_json(file_json, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7e41a6-c278-485d-b2b0-7c073bc62a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.iloc[:160,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85421759-7d79-406d-b612-493cd48c967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b169fa01-fbcf-4dfd-97ca-0cd3b5780263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Paragraphs and labels\n",
    "paragraphs = df_sub['selftext'].values\n",
    "labels = []\n",
    "\n",
    "for ii in range(df_sub.shape[0]):\n",
    "    misconception_label = df_sub.at[ii,'misconception']\n",
    "    unclear_knowledge_label = df_sub.at[ii, 'unclear knowledge']\n",
    "    if (misconception_label != 'n/a') or (unclear_knowledge_label != 'n/a'):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f0255f4-04ee-4626-a56a-c2b115ec2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "base_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Custom model with sentence and paragraph-level prediction\n",
    "class SentenceToParagraphModel(nn.Module):\n",
    "    def __init__(self, base_model, hidden_dim=768):\n",
    "        super(SentenceToParagraphModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.sentence_fc = nn.Linear(hidden_dim, 1)  # Sentence-level prediction (binary)\n",
    "        self.paragraph_fc = nn.Linear(hidden_dim, 1)  # Paragraph-level prediction (binary)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERT model output for each token in each sentence\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sentence_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token as sentence embedding\n",
    "\n",
    "        # Sentence-level predictions\n",
    "        sentence_logit = self.sentence_fc(sentence_embedding).squeeze(-1)\n",
    "        return sentence_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae00839-1cdd-4276-a972-4621bba6018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the custom model\n",
    "model = SentenceToParagraphModel(base_model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e015308-1baa-428c-84f4-e9c04ed96704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceToParagraphModel(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sentence_fc): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (paragraph_fc): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7b684e5-e410-4478-bed6-9516ab01c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241bc66-cbee-4e5c-ade1-620c5ed7770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27e6ec8f-991b-4146-8803-2a270925165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8279798725619912\n",
      "Epoch 2, Loss: 0.695451258122921\n",
      "Epoch 3, Loss: 0.6947487272322178\n",
      "Epoch 4, Loss: 0.6944276183843613\n",
      "Epoch 5, Loss: 0.694217799976468\n",
      "Epoch 6, Loss: 0.6940627809613943\n",
      "Epoch 8, Loss: 0.6938336815685033\n",
      "Epoch 9, Loss: 0.6937485881149769\n",
      "Epoch 10, Loss: 0.6936761248856783\n"
     ]
    }
   ],
   "source": [
    "# Example: Training loop for paragraph-level supervision\n",
    "model.train()\n",
    "for epoch in range(10):  # Example for 3 epochs\n",
    "    total_loss = 0\n",
    "    for paragraph, label in zip(paragraphs, labels):\n",
    "        # Split paragraph into sentences\n",
    "        sentences = paragraph.split('.')  # Simplified sentence splitting\n",
    "        sentences = [s.strip() for s in sentences if s]\n",
    "\n",
    "        sentence_probs = []\n",
    "        \n",
    "        # Predict each sentence separately\n",
    "        for sentence in sentences:\n",
    "            # Tokenize the sentence\n",
    "            inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "            input_ids = inputs[\"input_ids\"].to(\"cuda\")  # Move input to GPU\n",
    "            attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "            \n",
    "            # Forward pass for sentence\n",
    "            #sentence_logit = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "            sentence_logit = model(input_ids, attention_mask)\n",
    "            sentence_prob = torch.sigmoid(sentence_logit)\n",
    "            sentence_probs.append(sentence_prob)\n",
    "\n",
    "        # Combine sentence probabilities (using OR-like aggregation)\n",
    "        paragraph_prob = 1 - torch.prod(1 - torch.stack(sentence_probs))\n",
    "        # Ensure paragraph_prob is reshaped to match label_tensor shape\n",
    "        paragraph_prob = paragraph_prob.view(1)  # Reshape to (1,) if it's a scalar\n",
    "\n",
    "        # Compute loss using the paragraph label\n",
    "        label_tensor = torch.tensor([label], dtype=torch.float).to(paragraph_prob.device)\n",
    "        paragraph_loss = criterion(paragraph_prob, label_tensor)\n",
    "        total_loss += paragraph_loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        paragraph_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(paragraphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29d6214f-5974-4aa3-bed6-19a0e9f9c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Step 2: Set the model to evaluation mode\n",
    "\n",
    "# Example input (a long text you want to predict on)\n",
    "input_text = df.at[191,'selftext']\n",
    "\n",
    "# Step 3: Tokenize and prepare the input data\n",
    "sentences = input_text.split('.')  # Break into sentences\n",
    "sentences = [s.strip() for s in sentences if s]\n",
    "\n",
    "# Store predictions\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        \n",
    "        # Move inputs to GPU if applicable\n",
    "        input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        # Step 4: Make predictions\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities (if using binary classification)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        # Store the predictions\n",
    "        predictions.append(probabilities.item())\n",
    "\n",
    "# Step 5: Interpret the output\n",
    "# For example, if your threshold for labeling a sentence as having a misconception is 0.5:\n",
    "#labels = [\"Mistake\" if prob > 0.5 else \"No Mistake\" for prob in predictions]\n",
    "\n",
    "# Output the results\n",
    "#for sentence, prob, label in zip(sentences, predictions, labels):\n",
    "#    print(f\"Sentence: '{sentence}' - Probability: {prob:.4f} - Label: {label}\")\n",
    "paragraph_prob = 1 - np.prod(1 - np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf25350c-b0ab-4b26-aaad-2914fc339913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1966353667958174e-05"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd3862d0-052c-4643-a553-6ab2f537f2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'created_utc', 'title', 'selftext', 'note', 'jurisdictions',\n",
       "       'relevance', 'poster's legal status', 'misconception',\n",
       "       'unclear knowledge', 'category', 'background', 'underlined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ab7c249-8ab2-4579-a8ba-041589af0b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n/a'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[191,'misconception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "181666bc-2b1b-43ec-aba5-e417ff091dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n/a'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[191,'unclear knowledge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d9979-28c1-4d26-b5a9-3e23aa11aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and optimizer states\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epoch,  # Optionally save the current epoch\n",
    "}, 'model_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261624d7-2e82-4be3-a831-7a7eb616ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer states\n",
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "# Load the model state\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Load the optimizer state\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Optionally load the last epoch\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# then, continue training with more code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd7df8-c902-4cfc-900f-c85a50508ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
